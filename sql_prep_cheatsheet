#SQL

#NORMALIZATION
1NF (First Normal Form) Rules
Each table cell should contain a single value.
Each record needs to be unique.

The data depends on the key [1NF],
the whole key [2NF] + [1NF]
and nothing but the key [3NF] + [2NF].
BCNF - Boyce-Codd, When Primary key = All other columns 

#KEYS
super keys: all kind of keys including redundant columns.
candidate keys: unique keys that doesn't need to include redundant keys, subset of super keys.
primary keys: one unique key that are taken from candidate keys.
alternate keys: all other candidate keys that are not chosen as a primary one.
Compound(can have foreigh keys)
Composite(may or may not have foreighn keys)
Surrogate key -an artificial key which aims to uniquely identify each record
Foreighn key can be null

https://www.guru99.com/dbms-keys.html

#INDEXES
B-TREE (Always balanced, depth is equal at every leaf)
Tree + Double LinkedList
O(log(n)) - for B-tree,

why index might be slow?
An index lookup requires three steps: (1) the tree traversal; (2) following the leaf node chain; (3) fetching the table data.

Even though the two-index solution delivers very good select performance as well, the single-index solution is preferable.
It not only saves storage space, but also the maintenance overhead for the second index.
The fewer indexes a table has, the better the insert, delete and update performance.

The query optimizer, or query planner, is the database component that transforms an SQL statement into an execution plan. This process is also called compiling or parsing. There are two distinct optimizer types.
Cost-based optimizers (CBO) generate many execution plan variations and calculate a cost value for each plan. The cost calculation is based on the operations in use and the estimated row numbers. In the end the cost value serves as the benchmark for picking the “best” execution plan.
Rule-based optimizers (RBO) generate the execution plan using a hard-coded rule set. Rule based optimizers are less flexible and are seldom used today.

The efficiency of an INDEX RANGE SCAN may vary over a wide range—especially when followed by a table access. Using an index does not automatically mean a statement is executed in the best way possible.

PostgreSQL and the Oracle database trust the DETERMINISTIC or IMMUTABLE declarations—that means they trust the developer.

Indx types:
B-Tree - For most datatypes and queries
GIN - For JSONB/hstore/arrays
GiST - For full text search and geospatial datatypes
SP-GiST - For larger datasets with natural but uneven clustering
BRIN - For really large datasets that line up sequentially
Hash - For equality operations, and generally B-Tree still what you want here

#STATISTICS
VACUUM -- garbage-collect and optionally analyze a database
VACUUM ANALYZE performs a VACUUM and then an ANALYZE for each selected table.

High cardinality means that the column contains a large percentage of totally unique values.
Low cardinality means that the column contains a lot of “repeats” in its data range
Cardinality relationships between tables can take the form of one-to-one,
one-to-many (whose reversal is many-to-one) or many-to-many. 

#TUNING/OPTIMIZATION
In all reality, there are only a few cases in which the actual values affect the execution plan. You should therefore use bind parameters if in doubt—just to prevent SQL injections.
A partial index is useful for commonly used where conditions that use constant values

# WAREHOUSE CONCEPTS
DIMENSIONAL MODELLING
Granularity is the lowest level of information stored in the table.
Fact table measurements and dimenstion table attributes. 

SCD types:
SCD 1:
SCD 2:
SCD 3:
SCD 4:
SCD 5:
SCD 6:

Steps for dimentional modelling:
1) Identify Business Process: Business process is they root of the task, so planning starts from there.
2) Identify Grain (level of detail) : Atomicity, Granularity
3) Identify Dimensions: Who, What, Where
4) Identify Facts: When, How Much
5) Build Star

**Characteristics of Star Schema:
Star schema model are deliberatly denormalized to speed up the process,
Dimensional Tables are not normalized.
The dimension table should contain the set of attributes.
Dimension table is joined to only Fact tables. They are not joined to each other.
Fact table stores keys from dimension tables and measure.
The Star schema is easy to understand and provides optimal disk usage.
Surrogate keys are preferred over natural keys if it is composite.

Benifits of Data warehouse Star Schema:
Simple queries: Join conditions are simple joins in this schema
Simplified business logics: This model simplifies common reporting business logics
Performance: This model provides performance enhancements for reporting applications
Fast aggregation
Feeding cubes: This model is generally used by OLAP systems to build cubes. Building cube is very fast process

Disadvantages of Data warehouse Star Schema:
The main disadvantages is, that data integrity is not enforced as in OLTP databases
This is not flexible inters of analytical application as normalized databases.
This model don’t support many to many relationship between business entities. These types of relationships are simplified in star schema

**Snowflake schema
Benefits of Data Warehouse snowflake schema
Snowflake model is in same family as the star schema. In fact, it is a special case of star schema. Some of the benifits includes:

Some OLAP multidimensional model tools are optimized to use snowflake schema
Normalizing table saves the storage
Improvement in query performance due to minimized disk storage and joining smaller lookup tables
Disadvantages of Data Warehouse Snowflake schema
Additional maintenance efforts needed due to the increase number of lookup tables
SQL queries would have more joins in order to fetch the records
Data loads into the snowflake model must be highly controlled and managed to avoid update and insert anomalies

OLAP CUBES
Data Vault

#STATISTICS
Mode, value that appears most often.
Mean, avg.
Median, middle of the sorted.
